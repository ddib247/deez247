{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ddib247/deez247/blob/main/ContextOS_Manager_Notebook.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# %% [markdown]\n",
        "# # ContextOS Manager // Release Candidate 1\n",
        "# **Role:** The Manager (Data Processing & Analysis)\n",
        "# **Objective:** Process \"DreamerDump\" inputs, perform NLP clustering, and update the \"TaskBacklog\".\n",
        "# **Version:** v0.3.1 (JSON-Aware & Schema Aligned)\n",
        "\n",
        "# %% [code]\n",
        "# ==========================================\n",
        "# CELL 1: SETUP & CONFIGURATION\n",
        "# ==========================================\n",
        "import os\n",
        "import pandas as pd\n",
        "import nltk\n",
        "import json\n",
        "from google.colab import drive\n",
        "\n",
        "# --- USER CONFIGURATION (Simple Variables) ---\n",
        "# @title Colab Configuration\n",
        "# Where does your ContextOS project file folder live in Drive?\n",
        "DRIVE_FOLDER = \"/content/drive/MyDrive/Area 1225/Project 1\" # @param {type:\"string\"}\n",
        "DB_FILENAME = \"ContextOS_Master_DB\" # @param {type:\"string\"}\n",
        "\n",
        "# Constants for File Paths\n",
        "BASE_PATH = f\"/content/drive/My Drive/{DRIVE_FOLDER}\"\n",
        "DREAMER_DUMP_PATH = f\"{BASE_PATH}/DreamerDump.csv\"\n",
        "BACKLOG_PATH = f\"{BASE_PATH}/TaskBacklog.csv\"\n",
        "\n",
        "# Mount Google Drive\n",
        "print(\"üîå Connecting to Google Drive...\")\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Verify Directory\n",
        "if not os.path.exists(BASE_PATH):\n",
        "    print(f\"‚ö†Ô∏è Warning: Folder '{BASE_PATH}' not found.\")\n",
        "    print(f\"   Creating '{BASE_PATH}' now...\")\n",
        "    os.makedirs(BASE_PATH, exist_ok=True)\n",
        "else:\n",
        "    print(f\"‚úÖ ContextOS Folder Found: {BASE_PATH}\")\n",
        "\n",
        "# Download NLTK resources (Run once)\n",
        "print(\"üìö Loading NLP Libraries...\")\n",
        "nltk.download('punkt', quiet=True)\n",
        "nltk.download('stopwords', quiet=True)\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "from collections import Counter\n",
        "\n",
        "print(\"üöÄ System Ready.\")\n",
        "\n",
        "# %% [code]\n",
        "# ==========================================\n",
        "# CELL 2: THE MANAGER INTELLIGENCE (FUNCTIONS)\n",
        "# ==========================================\n",
        "\n",
        "def load_data():\n",
        "    \"\"\"Loads the CSV databases. Creates them if missing.\"\"\"\n",
        "    data = {}\n",
        "\n",
        "    # Load DreamerDump\n",
        "    # Schema matches 'context_bridge.gs':\n",
        "    # [Dream_ID, Timestamp, Source_Type, Core_Intent, JSON_Payload, Status]\n",
        "    if os.path.exists(DREAMER_DUMP_PATH):\n",
        "        try:\n",
        "            data['dreams'] = pd.read_csv(DREAMER_DUMP_PATH)\n",
        "            print(f\"üìñ Loaded {len(data['dreams'])} dreams.\")\n",
        "        except Exception as e:\n",
        "            print(f\"‚ö†Ô∏è Error loading DreamerDump: {e}\")\n",
        "            data['dreams'] = pd.DataFrame(columns=[\"Dream_ID\", \"Timestamp\", \"Source_Type\", \"Core_Intent\", \"JSON_Payload\", \"Status\"])\n",
        "    else:\n",
        "        print(\"‚ú® No DreamerDump found. Creating new dataframe.\")\n",
        "        data['dreams'] = pd.DataFrame(columns=[\"Dream_ID\", \"Timestamp\", \"Source_Type\", \"Core_Intent\", \"JSON_Payload\", \"Status\"])\n",
        "\n",
        "    # Load Backlog\n",
        "    if os.path.exists(BACKLOG_PATH):\n",
        "        try:\n",
        "            data['backlog'] = pd.read_csv(BACKLOG_PATH)\n",
        "            print(f\"üìã Loaded {len(data['backlog'])} backlog tasks.\")\n",
        "        except Exception as e:\n",
        "             print(f\"‚ö†Ô∏è Error loading Backlog: {e}\")\n",
        "             data['backlog'] = pd.DataFrame(columns=[\"ID\", \"Task Name\", \"Context_Tag\", \"Social_Req\", \"Opportunity_Score\", \"Visual_Reward\", \"Est_Duration\", \"Deadline\", \"Dynamic_Score\", \"Status\"])\n",
        "    else:\n",
        "        print(\"‚ú® No TaskBacklog found. Creating new dataframe.\")\n",
        "        # Schema matches v0.3.1 Backlog\n",
        "        data['backlog'] = pd.DataFrame(columns=[\"ID\", \"Task Name\", \"Context_Tag\", \"Social_Req\", \"Opportunity_Score\", \"Visual_Reward\", \"Est_Duration\", \"Deadline\", \"Dynamic_Score\", \"Status\"])\n",
        "\n",
        "    return data\n",
        "\n",
        "def extract_raw_text(row):\n",
        "    \"\"\"Extracts raw text stream from JSON payload for NLP analysis.\"\"\"\n",
        "    try:\n",
        "        payload = json.loads(row['JSON_Payload'])\n",
        "        return payload.get('content', {}).get('raw_stream', row['Core_Intent'])\n",
        "    except:\n",
        "        return str(row['Core_Intent'])\n",
        "\n",
        "def analyze_rabbit_holes(df_dreams):\n",
        "    \"\"\"\n",
        "    NLP Logic: Clusters keywords from the raw stream inside the JSON.\n",
        "    \"\"\"\n",
        "    if df_dreams.empty:\n",
        "        return {}\n",
        "\n",
        "    # Extract text from JSON\n",
        "    text_blob = \" \".join(df_dreams.apply(extract_raw_text, axis=1).tolist())\n",
        "\n",
        "    # Tokenize & Clean\n",
        "    tokens = word_tokenize(text_blob.lower())\n",
        "    stop_words = set(stopwords.words('english'))\n",
        "    clean_tokens = [word for word in tokens if word.isalnum() and word not in stop_words]\n",
        "\n",
        "    # Count Frequencies\n",
        "    freq = Counter(clean_tokens)\n",
        "    return freq.most_common(10)\n",
        "\n",
        "def promote_to_task(dream_row, backlog_df):\n",
        "    \"\"\"\n",
        "    Converts a Dream Row into a specific First Draft Task using JSON data.\n",
        "    \"\"\"\n",
        "    new_id = len(backlog_df) + 1\n",
        "\n",
        "    # Default values (Fallbacks)\n",
        "    task_name = f\"Draft: {dream_row['Core_Intent']}\"\n",
        "    context_tag = \"Home\"\n",
        "    est_duration = 15\n",
        "    visual_reward = 5\n",
        "\n",
        "    # Try to parse the JSON for smarter defaults\n",
        "    try:\n",
        "        payload = json.loads(dream_row['JSON_Payload'])\n",
        "\n",
        "        # 1. Extract the \"First Draft\" Task\n",
        "        if 'first_draft_tasks' in payload and len(payload['first_draft_tasks']) > 0:\n",
        "            draft = payload['first_draft_tasks'][0]\n",
        "            task_name = draft.get('task_name', task_name)\n",
        "            context_tag = draft.get('context_tag', context_tag)\n",
        "            est_duration = draft.get('est_duration', est_duration)\n",
        "\n",
        "        # 2. Extract Visual Reward Potential\n",
        "        if 'analysis' in payload:\n",
        "            visual_reward = payload['analysis'].get('visual_reward_potential', visual_reward)\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"   ‚ö†Ô∏è JSON Parse Error for Dream {dream_row.get('Dream_ID', '?')}: {e}\")\n",
        "\n",
        "    # Construct the Row\n",
        "    new_task = {\n",
        "        \"ID\": f\"{new_id:03d}\",\n",
        "        \"Task Name\": task_name,\n",
        "        \"Context_Tag\": context_tag,\n",
        "        \"Social_Req\": \"Solo\", # Default to Solo for focused work\n",
        "        \"Opportunity_Score\": 5,\n",
        "        \"Visual_Reward\": visual_reward,\n",
        "        \"Est_Duration\": est_duration,\n",
        "        \"Deadline\": \"\", # Manager adds this manually later\n",
        "        \"Dynamic_Score\": 0,\n",
        "        \"Status\": \"Pending\"\n",
        "    }\n",
        "    return new_task\n",
        "\n",
        "print(\"üß† Manager Logic Loaded (v0.3.1).\")\n",
        "\n",
        "# %% [code]\n",
        "# ==========================================\n",
        "# CELL 3: EXECUTION (RUN THE MANAGER)\n",
        "# ==========================================\n",
        "\n",
        "# 1. Load the Brain\n",
        "db = load_data()\n",
        "\n",
        "# 2. Analyze Dreams (The \"Review\" Phase)\n",
        "if not db['dreams'].empty:\n",
        "    print(\"\\nüîç Analyzing Rabbit Holes (Top Keywords):\")\n",
        "    themes = analyze_rabbit_holes(db['dreams'])\n",
        "    for word, count in themes:\n",
        "        print(f\"   - {word}: {count} occurrences\")\n",
        "\n",
        "# 3. Auto-Promotion\n",
        "unprocessed = db['dreams'][db['dreams']['Status'] == \"Unprocessed\"]\n",
        "\n",
        "if not unprocessed.empty:\n",
        "    print(f\"\\n‚öôÔ∏è Processing {len(unprocessed)} new dreams...\")\n",
        "    new_tasks = []\n",
        "\n",
        "    for index, row in unprocessed.iterrows():\n",
        "        # Create Task\n",
        "        task = promote_to_task(row, db['backlog'])\n",
        "        new_tasks.append(task)\n",
        "\n",
        "        # Mark Dream as Processed\n",
        "        db['dreams'].at[index, 'Status'] = \"Processed\"\n",
        "        print(f\"   -> Promoted: {task['Task Name']} (Ctx: {task['Context_Tag']})\")\n",
        "\n",
        "    # Append to Backlog\n",
        "    new_task_df = pd.DataFrame(new_tasks)\n",
        "    db['backlog'] = pd.concat([db['backlog'], new_task_df], ignore_index=True)\n",
        "\n",
        "    # Save Changes to Drive\n",
        "    # NOTE: Uncomment these lines to actually write to your Drive files\n",
        "    # db['dreams'].to_csv(DREAMER_DUMP_PATH, index=False)\n",
        "    # db['backlog'].to_csv(BACKLOG_PATH, index=False)\n",
        "    print(\"üíæ Changes simulated. Uncomment save lines to write to Drive.\")\n",
        "\n",
        "else:\n",
        "    print(\"\\n‚úÖ All dreams are processed.\")\n",
        "\n",
        "# %% [code]\n",
        "# ==========================================\n",
        "# CELL 4: OPTIONAL SELF-REVIEW (DEBUGGER)\n",
        "# ==========================================\n",
        "# Run this cell to check data integrity or logic errors\n",
        "\n",
        "def diagnostic_review(data):\n",
        "    print(\"--- ü©∫ DATA DIAGNOSTICS ---\")\n",
        "\n",
        "    # Check Backlog Health\n",
        "    bl = data['backlog']\n",
        "    print(f\"Task Backlog: {len(bl)} rows\")\n",
        "\n",
        "    if 'Dynamic_Score' in bl.columns:\n",
        "        null_scores = bl['Dynamic_Score'].isnull().sum()\n",
        "        if null_scores > 0:\n",
        "            print(f\"‚ö†Ô∏è ALERT: {null_scores} tasks have no Dynamic Score.\")\n",
        "\n",
        "    # Check Context Tags\n",
        "    if 'Context_Tag' in bl.columns:\n",
        "        tags = bl['Context_Tag'].unique()\n",
        "        print(f\"Active Context Tags: {tags}\")\n",
        "\n",
        "    # Check Dream Parse\n",
        "    if not data['dreams'].empty:\n",
        "        sample_json = data['dreams'].iloc[0].get('JSON_Payload')\n",
        "        print(f\"Sample Dream JSON Preview: {str(sample_json)[:50]}...\")\n",
        "\n",
        "    print(\"---------------------------\")\n",
        "\n",
        "# Run Diagnostic\n",
        "diagnostic_review(db)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üîå Connecting to Google Drive...\n",
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "‚úÖ ContextOS Folder Found: /content/drive/My Drive//content/drive/MyDrive/Area 1225/Project 1\n",
            "üìö Loading NLP Libraries...\n",
            "üöÄ System Ready.\n",
            "üß† Manager Logic Loaded (v0.3.1).\n",
            "‚ú® No DreamerDump found. Creating new dataframe.\n",
            "‚ú® No TaskBacklog found. Creating new dataframe.\n",
            "\n",
            "‚úÖ All dreams are processed.\n",
            "--- ü©∫ DATA DIAGNOSTICS ---\n",
            "Task Backlog: 0 rows\n",
            "Active Context Tags: []\n",
            "---------------------------\n"
          ]
        }
      ],
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8T5y8bd5thWy",
        "outputId": "a6707904-655a-45f8-8028-866c802609e6"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2d1c9297"
      },
      "source": [
        "### Adding a Sample Dream to `DreamerDump`\n",
        "\n",
        "This cell demonstrates how to manually add a new 'dream' entry to the `db['dreams']` DataFrame. Each dream should ideally have a unique `Dream_ID`, `Timestamp`, `Source_Type`, `Core_Intent`, a `JSON_Payload` (which is a JSON string), and a `Status` (initially 'Unprocessed')."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        },
        "id": "8ed946c6",
        "outputId": "a5dc7373-d568-4b24-b4c1-3738b2289843"
      },
      "source": [
        "import uuid\n",
        "import datetime\n",
        "import json\n",
        "\n",
        "# Define a new sample dream\n",
        "new_dream_data = {\n",
        "    \"Dream_ID\": str(uuid.uuid4()), # Generate a unique ID\n",
        "    \"Timestamp\": datetime.datetime.now().isoformat(),\n",
        "    \"Source_Type\": \"Manual_Input\",\n",
        "    \"Core_Intent\": \"Explore new project idea: AI-powered task prioritization\",\n",
        "    \"JSON_Payload\": json.dumps({\n",
        "        \"content\": {\n",
        "            \"raw_stream\": \"I was thinking about how to make task management more efficient. What if an AI could look at my notes, emails, and calendar to suggest the most important tasks? It could identify dependencies and potential blockers. This needs to be explored. Maybe a visual dashboard would help.\"\n",
        "        },\n",
        "        \"first_draft_tasks\": [\n",
        "            {\n",
        "                \"task_name\": \"Research AI task prioritization algorithms\",\n",
        "                \"context_tag\": \"Research\",\n",
        "                \"est_duration\": 60\n",
        "            }\n",
        "        ],\n",
        "        \"analysis\": {\n",
        "            \"visual_reward_potential\": 8\n",
        "        }\n",
        "    }),\n",
        "    \"Status\": \"Unprocessed\"\n",
        "}\n",
        "\n",
        "# Convert the new dream into a DataFrame row\n",
        "new_dream_df = pd.DataFrame([new_dream_data])\n",
        "\n",
        "# Append to the existing dreams DataFrame\n",
        "db['dreams'] = pd.concat([db['dreams'], new_dream_df], ignore_index=True)\n",
        "\n",
        "print(\"New dream added to db['dreams']:\")\n",
        "display(db['dreams'].tail())\n",
        "\n",
        "# IMPORTANT: To make this change persistent, you must uncomment and run the following line in Cell 3:\n",
        "# db['dreams'].to_csv(DREAMER_DUMP_PATH, index=False)\n"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "New dream added to db['dreams']:\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "                               Dream_ID                   Timestamp  \\\n",
              "0  21863f85-a5a6-4576-b176-a2a5ae9ce45e  2025-12-24T09:51:59.784023   \n",
              "\n",
              "    Source_Type                                        Core_Intent  \\\n",
              "0  Manual_Input  Explore new project idea: AI-powered task prio...   \n",
              "\n",
              "                                        JSON_Payload       Status  \n",
              "0  {\"content\": {\"raw_stream\": \"I was thinking abo...  Unprocessed  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-d615b584-84a6-4e04-afc3-1510d3b197fe\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Dream_ID</th>\n",
              "      <th>Timestamp</th>\n",
              "      <th>Source_Type</th>\n",
              "      <th>Core_Intent</th>\n",
              "      <th>JSON_Payload</th>\n",
              "      <th>Status</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>21863f85-a5a6-4576-b176-a2a5ae9ce45e</td>\n",
              "      <td>2025-12-24T09:51:59.784023</td>\n",
              "      <td>Manual_Input</td>\n",
              "      <td>Explore new project idea: AI-powered task prio...</td>\n",
              "      <td>{\"content\": {\"raw_stream\": \"I was thinking abo...</td>\n",
              "      <td>Unprocessed</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-d615b584-84a6-4e04-afc3-1510d3b197fe')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-d615b584-84a6-4e04-afc3-1510d3b197fe button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-d615b584-84a6-4e04-afc3-1510d3b197fe');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"# db['dreams']\",\n  \"rows\": 1,\n  \"fields\": [\n    {\n      \"column\": \"Dream_ID\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"21863f85-a5a6-4576-b176-a2a5ae9ce45e\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Timestamp\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"2025-12-24T09:51:59.784023\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Source_Type\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"Manual_Input\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Core_Intent\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"Explore new project idea: AI-powered task prioritization\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"JSON_Payload\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"{\\\"content\\\": {\\\"raw_stream\\\": \\\"I was thinking about how to make task management more efficient. What if an AI could look at my notes, emails, and calendar to suggest the most important tasks? It could identify dependencies and potential blockers. This needs to be explored. Maybe a visual dashboard would help.\\\"}, \\\"first_draft_tasks\\\": [{\\\"task_name\\\": \\\"Research AI task prioritization algorithms\\\", \\\"context_tag\\\": \\\"Research\\\", \\\"est_duration\\\": 60}], \\\"analysis\\\": {\\\"visual_reward_potential\\\": 8}}\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Status\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"Unprocessed\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {}
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}